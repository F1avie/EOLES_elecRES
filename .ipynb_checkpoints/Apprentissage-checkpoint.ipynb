{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b0626a",
   "metadata": {},
   "source": [
    "## Récupération des data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_X_Y.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7229a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4561b",
   "metadata": {},
   "source": [
    "- verification des contraintes physique sur notre jeu de données simulé\n",
    "\n",
    "- la prediction par les technologie hors stockage - la demande représente :\n",
    "    - ce que l'on peut stocker au maximum si > 0\n",
    "    - ce que l'on doit destocker si < 0\n",
    "    \n",
    " - donc prediction par les technologie hors stockage - la demande - delta stock doit etre > 0 ,avec delta stoks la somme de ce que l'on à stocker ou destocker dans la journée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ac9ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6081/1923266094.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check_constraint_prod_stock :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m180\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m74.14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12499.09\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msomme_stock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock_day_battery'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock_day_methanation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock_day_phs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contrainte_prod_stock'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'production_nette'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'production stock'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msomme_stock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# check_constraint_prod_stock :\n",
    "volume= pd.Series([180 ,74.14, 12499.09]) \n",
    "somme_stock = data['stock_day_battery']*volume[1]/100+ data['stock_day_methanation']*volume[2]/100+ data['stock_day_phs']*volume[0]/100\n",
    "data['contrainte_prod_stock'] = (data['production_nette']-data['production stock'] - somme_stock) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['contrainte_prod_stock'] < 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce61d7",
   "metadata": {},
   "source": [
    "- on remarque que les errue apparaissent uniquement quand la production nette est négative or ceci n'est paas possible en réalité (résultats d'arrondies).\n",
    "- la contrainte est alors égale à la production nette ce qui serait 0 si il n'y avait pas l'erreur de la production nette."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76baacee",
   "metadata": {},
   "source": [
    "## Données d'entrées (X) / de sorties (Y) du réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e502b549",
   "metadata": {},
   "source": [
    " - production_nette = production exédentaire = $\\sum_{tec} production - demand$\n",
    " - Stored tec = état des stocks au début de la journée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7662950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['production_nette', 'production stock', 'Stored phs', 'Stored battery', 'Stored methanation', 'days' ]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0745528",
   "metadata": {},
   "source": [
    "- stock_day_tec = quantité stocké dans la journée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[['stock_day_phs', 'stock_day_battery', 'stock_day_methanation', 'cost']]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff968fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pas mis à jour\n",
    "# pour modèle 3\n",
    "Y_funk = data[[ 'Stored24phs', 'Stored24battery', 'Stored24methanation', 'production_nette', 'Stored phs', 'Stored battery', 'Stored methanation', 'cost']]\n",
    "Y_funk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5e0624",
   "metadata": {},
   "source": [
    "### Normalisation des données d'entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "XSc= scaler.transform(X)\n",
    "XSc = pd.DataFrame(XSc, index =X.index, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174cf15",
   "metadata": {},
   "source": [
    "## Jeu de test et jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3928c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(XSc,Y,test_size=0.25,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31cdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version array pour utiliser la fonction funk\n",
    "X_funk_train,X_funk_test,Y_funk_train,Y_funk_test = train_test_split(np.array(XSc),np.array(Y_funk),test_size=0.25,random_state=13)\n",
    "X_funk_train = np.array(X_funk_train)\n",
    "X_funk_test = np.array(X_funk_test)\n",
    "Y_funk_train = np.array(Y_funk_train)\n",
    "Y_funk_test = np.array(Y_funk_test)\n",
    "x_funk_train, x_funk_val, y_funk_train, y_funk_val = train_test_split(np.array(X_funk_train), np.array(Y_funk_train), test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c65fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_funk_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_funk_train_strat = np.array(X_train_strat)\n",
    "X_funk_test_strat = np.array(X_test_strat)\n",
    "Y_funk_train_strat = np.array(Y_funk[365:])\n",
    "Y_funk_test_strat = np.array(Y_funk[0:365])\n",
    "x_funk_train_strat, x_funk_val_strat, y_funk_train_strat, y_funk_val_strat = train_test_split(np.array(X_funk_train), np.array(Y_funk_train), test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233d404",
   "metadata": {},
   "source": [
    "## Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some useful methods\n",
    "\n",
    "def compile_model(model, lr,loss, optimiseur, metrics, loss_weights, run_eagerly):\n",
    "    model.compile(loss = loss,optimizer=optimiseur,metrics = metrics, loss_weights= loss_weights, run_eagerly = run_eagerly)\n",
    "def train_model(model,X_train, Y_train, epoch, val):\n",
    "    model.fit (X_train, Y_train, epochs = epoch, validation_split = val)\n",
    "def train_model_funk(model, X_trainf, Y_trainf, epoch, val_data):\n",
    "    model.fit (X_trainf, Y_trainf, epochs = epoch, validation_data = val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred ( Y_testr, predr ):\n",
    "    fig0 = go.Figure()\n",
    "    fig0.add_traces(go.Scatter( x = Y_testr.index, y = Y_testr['stock_day_phs'], mode='lines', name = 'phs real'))\n",
    "    fig0.add_traces(go.Scatter(x = predr.index, y = predr['stock_day_phs'], mode='lines', name = 'phs predicted'))\n",
    "    fig0.show()\n",
    "    fig1 = go.Figure()\n",
    "    fig1.add_traces(go.Scatter( x = Y_testr.index, y = Y_testr['stock_day_battery'], mode='lines', name = 'battery real'))\n",
    "    fig1.add_traces(go.Scatter(x = predr.index, y = predr['stock_day_battery'], mode='lines', name = 'battery predicted'))\n",
    "    fig1.show()\n",
    "    fig2 = go.Figure()\n",
    "    fig2.add_traces(go.Scatter( x = Y_testr.index, y = Y_testr['stock_day_methanation'], mode='lines', name = 'methanation real'))\n",
    "    fig2.add_traces(go.Scatter(x = predr.index, y = predr['stock_day_methanation'], mode='lines', name = 'methanation predicted'))\n",
    "    fig2.show()\n",
    "    fig3 = go.Figure()\n",
    "    fig3.add_traces(go.Scatter( x = Y_testr.index, y = Y_testr['cost'], mode='lines', name = 'cost real * 10000'))\n",
    "    fig3.add_traces(go.Scatter(x = predr.index, y = predr['cost'], mode='lines', name = 'cost predicted *10000'))\n",
    "    fig3.show()\n",
    "    print('total cost real :', np.sum(Y_testr['cost'])/10000)\n",
    "    print('total cost predicted :', np.sum(predr['cost'])/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contrainte qui n'a plus vriament de sens\n",
    "def check_constraint_percent(predr):\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_phs\"]>100])\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_phs\"]<-100])\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_battery\"]>100])\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_battery\"]<-100])\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_methanation\"]>100])\n",
    "    print(\"liste des jours ou le stockage est impossible : \", predr[predr[\"stock_day_methanation\"]<-100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e5a65",
   "metadata": {},
   "source": [
    "### 1/ Premier modèle construction \"classique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39362ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(input_size, output_size):\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(128, activation = 'relu', input_shape = input_size),\n",
    "    layers.Dropout(0.3, seed = 2),\n",
    "    layers.Dense(128, activation = 'swish'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'swish'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'swish'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dense(output_size)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0089c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = [X_train.shape[1]]\n",
    "output_size = Y_train.shape[1]\n",
    "lr = 0.001\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimiseur = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "metrics = ['accuracy']\n",
    "loss_weights = 1\n",
    "run_eagerly = False\n",
    "epoch = 10\n",
    "val = 0.2\n",
    "\n",
    "model_1 = build_model1 (input_size, output_size)\n",
    "model_1.summary()\n",
    "model = model_1\n",
    "compile_model(model, lr,loss, optimiseur, metrics,  loss_weights, run_eagerly)\n",
    "train_model(model,X_train, Y_train, epoch, val)\n",
    "print(\"Score jeu test : [loss, accuracy]\", model_1.evaluate(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ac6f2",
   "metadata": {},
   "source": [
    "##### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3fba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.DataFrame(model_1.predict(X_test))\n",
    "pred_1.columns = ['stock_day_phs', 'stock_day_battery','stock_day_methanation','cost']\n",
    "pred_1.index = Y_test.index\n",
    "pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_testr = Y_test.sort_index()\n",
    "pred_1r = pred_1.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_testr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(Y_testr, pred_1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffdf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_constraint_percent(pred_1r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c20c4",
   "metadata": {},
   "source": [
    "### 2/ Deuxième modèle avec fonction d'activation sigmoid (pour restreindre les sorties en pourcentage)\n",
    "#### NB remplacé ici pas une tangente hyperbolique pour contraindre entre -1 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(input_size):\n",
    "    inputs = keras.Input(shape=(input_size))\n",
    "    dense1 = layers.Dense(128, activation=\"relu\")\n",
    "    x = dense1(inputs)\n",
    "    x = layers.Dropout(0.3, seed = 2)(x)\n",
    "    x = layers.Dense(128, activation = 'swish')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    x = layers.Dense(128, activation = 'swish')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    branchPourcent = layers.Dense(3, activation = \"tanh\")(x)*100\n",
    "    branchCost = layers.Dense(1, activation = 'relu')(x)\n",
    "    outputs =  layers.concatenate([branchPourcent,branchCost])\n",
    "    model = keras.Model(inputs, outputs, name=\"model_Sigmoid\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "lr = 0.001\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimiseur = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "metrics = ['accuracy']\n",
    "loss_weights = 1\n",
    "run_eagerly = False\n",
    "epoch = 10\n",
    "val = 0.2\n",
    "\n",
    "model_2 = build_model2 (input_size)\n",
    "model_2.summary()\n",
    "model = model_2\n",
    "compile_model(model, lr,loss, optimiseur, metrics, loss_weights, run_eagerly)\n",
    "train_model(model,X_train, Y_train, epoch, val)\n",
    "print(\"Score jeu test : [loss, accuracy]\", model_2.evaluate(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55616159",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = pd.DataFrame(model_2.predict(X_test))\n",
    "pred_2.columns = ['stock_day_phs', 'stock_day_battery','stock_day_methanation','cost']\n",
    "pred_2.index = Y_test.index\n",
    "print(pred_2)\n",
    "Y_testr = Y_test.sort_index()\n",
    "pred_2r = pred_2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeae1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(Y_testr, pred_2r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_constraint_percent(pred_2r)\n",
    "# problème de pourcentage réglé youpi ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cbc83",
   "metadata": {},
   "source": [
    "### 3/ Modèle 2 avec loss personnalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(input_size):\n",
    "    inputs = keras.Input(shape=(input_size))\n",
    "    dense1 = layers.Dense(128, activation=\"relu\")\n",
    "    x = dense1(inputs)\n",
    "    x = layers.Dropout(0.3, seed = 2)(x)\n",
    "    x = layers.Dense(128, activation = 'swish')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    x = layers.Dense(128, activation = 'swish')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    x = layers.Dense(128, activation = 'relu')(x)\n",
    "    branchPourcent = layers.Dense(3, activation = \"sigmoid\")(x)*100\n",
    "    branchBlind = layers.Dense(4)(x)*0\n",
    "    branch1 = layers.Concatenate()([branchPourcent,branchBlind])\n",
    "    branchCost = layers.Dense(1)(x)\n",
    "    outputs = [branch1,branchCost]\n",
    "    model = keras.Model(inputs, outputs, name=\"3\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c53975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funky_loss(y_true,y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    alpha = 5000\n",
    "    loss = mse(y_true[:,:3],y_pred[:,:3])\n",
    "\n",
    "    \n",
    "#     loss += alpha*mse(y_pred[y_pred <0],0.)\n",
    "#     loss += alpha*mse(y_pred[y_pred >100],100.)\n",
    "    \n",
    "#     if y_pred[:,0] <0:\n",
    "#         loss += alpha*mse(y_pred[0],0)\n",
    "#     elif y_pred[:,0] >100:\n",
    "#         loss += alpha*mse(y_pred[0],100)\n",
    "                                                                                                  \n",
    "#     if y_pred[:,1] <0:\n",
    "#         loss += alpha*mse(y_pred[1],0)\n",
    "#     elif y_pred[:,1] >100:\n",
    "#         loss += alpha*mse(y_pred[1],100)\n",
    "        \n",
    "#     if y_pred[:,2] <0:\n",
    "#         loss += alpha*mse(y_pred[2],0)\n",
    "#     elif y_pred[:,2] >100:\n",
    "#         loss += alpha*mse(y_pred[2],100)\n",
    "        \n",
    "    #ca marche pas car y_true et y_pred font la taille du batch !                                                                                              \n",
    "                                                                                                                \n",
    "    DeltaStored = (y_pred[:,:3]-y_true[:,4:]).numpy()\n",
    "    DeltaStored = DeltaStored.sum(axis=1)\n",
    "    \n",
    "    Ytmp = y_true[:,3]\n",
    "    loss += alpha*mse(Ytmp[Ytmp< DeltaStored],DeltaStored[Ytmp< DeltaStored])\n",
    "\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8891f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.1\n",
    "loss = [funky_loss,tf.keras.losses.MeanSquaredError()]\n",
    "optimiseur = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "metrics = [['accuracy'],['accuracy']]\n",
    "loss_weights = [1, 10]\n",
    "run_eagerly=True\n",
    "\n",
    "epoch = 2\n",
    "val = 0.2\n",
    "\n",
    "X_trainf = x_funk_train\n",
    "Y_trainf = [y_funk_train[:,:7],y_funk_train[:,7]] \n",
    "val_data = (x_funk_val,[y_funk_val[:,:7], y_funk_val[:,7]])\n",
    "\n",
    "input_size = X_trainf.shape[1]\n",
    "\n",
    "model_3 = build_model3(input_size)\n",
    "model_3.summary()\n",
    "\n",
    "model = model_3\n",
    "\n",
    "#pb ici à résoudre\n",
    "#compile_model(model, lr,loss, optimiseur, metrics,loss_weights, run_eagerly)\n",
    "#train_model_funk(model, X_trainf, Y_trainf , epoch, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimiseur = tf.keras.optimizers.RMSprop(learning_rate = 0.1)\n",
    "# model_3.compile(loss = loss,\n",
    "# optimizer = optimiseur,\n",
    "# metrics = [['accuracy'],['accuracy']],\n",
    "# loss_weights = [1, 10],\n",
    "# run_eagerly=True)\n",
    "\n",
    "# training = model_3.fit(x_funk_train,\n",
    "#                        [y_funk_train[:,:7],y_funk_train[:,7]],\n",
    "#                        epochs = 2,\n",
    "#                        validation_data=(x_funk_val, [y_funk_val[:,:7], y_funk_val[:,7]]))\n",
    "\n",
    "# print(\"Score jeu test : [loss, accuracy]\", model_3.evaluate(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3b6ca",
   "metadata": {},
   "source": [
    "# Etude d'un stratégie de stockage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a69ab",
   "metadata": {},
   "source": [
    "## Test des modèles sur des prédictions consécutives (Réalisable ?)\n",
    "\n",
    "- on coupe X_train et Ytrain à la main de manière à prédire sur une période contigue de l'année : ici l'an 2000. On apprend sur l'autre partie de l'année"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bfe29e",
   "metadata": {},
   "source": [
    "#### Prédiction contigue de la stratégie de stockage \n",
    "\n",
    "- l'idée est de prédire le stockage en fin de journée j+1 à partir des valeurs prédites en fin de journée j\n",
    "- ensuite il faut vérifier les contraintes de notre problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1437e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee966ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour partie stockage\n",
    "a =0 \n",
    "b =365\n",
    "X_train_strat = XSc[b: ] #utilisation des données renormalisé\n",
    "X_test_strat = XSc[a:b]\n",
    "Y_train_strat = Y[b:]\n",
    "Y_test_strat = Y[a:b]\n",
    "X_test_strat\n",
    "Y_train_strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_conti(model, Y_test, X, a, b):\n",
    "\n",
    "    pred2 = pd.DataFrame([], columns = Y_test.columns)\n",
    "    simu = X[a:b] #input avant sclalerisation !!! meme indice que le X_test_strat\n",
    "\n",
    "    for i in range(a,b):\n",
    "        sim = pd.DataFrame([simu.iloc[i]], columns = X.columns)\n",
    "\n",
    "        simSC = scaler.transform(sim)\n",
    "\n",
    "        simds = pd.DataFrame(simSC, columns = X.columns)\n",
    "        #print(simds)\n",
    "        pred = model.predict(simds)\n",
    "        #print(pred)\n",
    "        new_row = pd.Series({'stock_day_phs': pred[0][0], 'stock_day_battery': pred[0][1], 'stock_day_methanation' : pred[0][2], 'cost': pred[0][3]})\n",
    "        pred2 = pd.concat([pred2, new_row.to_frame().T], ignore_index=True)\n",
    "        simu.at[i+1, 'Stored phs'] = pred[0][0]\n",
    "        simu.at[i+1, 'Stored battery'] = pred[0][1]\n",
    "        simu.at[i+1, 'Stored methanation'] = pred[0][2]\n",
    "    return pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af89ae9",
   "metadata": {},
   "source": [
    "### Strat modèle 2 \n",
    "\n",
    "Il faut faire réaprendre le modèle car les jeux de test/ train sont différents pour la stratégie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f01704",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "lr = 0.001\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimiseur = tf.keras.optimizers.RMSprop(learning_rate = lr)\n",
    "metrics = ['accuracy']\n",
    "loss_weights = 1\n",
    "run_eagerly = False\n",
    "epoch = 10\n",
    "val = 0.2\n",
    "\n",
    "model_2 = build_model2 (input_size)\n",
    "model_2.summary()\n",
    "model = model_2\n",
    "compile_model(model, lr,loss, optimiseur, metrics, loss_weights, run_eagerly)\n",
    "train_model(model,X_train_strat, Y_train_strat, epoch, val)\n",
    "print(\"Score jeu test : [loss, accuracy]\", model_2.evaluate(X_test_strat,Y_test_strat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pred_conti(model_2, Y_test_strat,X, a, b)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1918d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafcec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred(Y_test_strat, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_constraint_percent(pred2)\n",
    "#validé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5d499",
   "metadata": {},
   "source": [
    "#### 2. La différence des stocks de la journée doit être inférieur à production résiduelle\n",
    "\n",
    "- si prod_nette > 0 : on peut stocker positivement MAIS on ne peut pas stocker plus : stock_24 - stock_0 (positif) < prod_nette (positive) : on stoke un peu moins que ce qu'on a en trop\n",
    "- si prod_nette < 0 : on doit destocker au moins cette quantité (ou plus) : stock_24 - stock_0 (negatif) < prod_nette (negatif) : on destocke plus que ce qu'on a besoin\n",
    "\n",
    "- Dans les 2 cas il faut verifier : stock_24 - stock_0 < prod_nette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def check_constraint_phisics(pred):\n",
    "    volume= pd.Series([180 ,74.14, 12499.09]) \n",
    "    pred2Tst = pred\n",
    "    pred2Tst[\"Stored phs\"] = pred[\"stock_day_phs\"]*volume[0]/100\n",
    "    pred2Tst[\"Stored battery\"] = pred['stock_day_battery']*volume[1]/100\n",
    "    pred2Tst[\"Stored methanation\"] = pred['stock_day_methanation']*volume[2]/100\n",
    "    Delta_Stored = pred2Tst[[\"Stored24phs\",\"Stored24battery\",'stock_day_methanation']][1:].reset_index(drop = True) - \\\n",
    "                   pred2Tst[[\"Stored phs\",\"Stored battery\",\"Stored methanation\"]][:-1].reset_index(drop = True)\n",
    "    Success = Delta_Stored.sum(axis=1)<data[1:365].reset_index(drop =True)[\"production_nette\"]\n",
    "    Delta_Stored.sum(axis=1)\n",
    "    return np.where(Success == False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0184db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''check_constraint_phisics(pred2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_constraint_phisics(pred2, a, b):\n",
    "    volume= pd.Series([180 ,74.14, 12499.09]) \n",
    "    somme_stock = pred2['stock_day_battery']*volume[1]/100+ pred2['stock_day_methanation']*volume[2]/100+ pred2['stock_day_phs']*volume[0]/100\n",
    "    data.iloc[a:b]['contrainte_prod_stock'] = (data.iloc[a:b]['production_nette']-data.iloc[a:b]['production stock'] - somme_stock) \n",
    "    print('affichage des erreur :' , data.iloc[a:b][data['contrainte_prod_stock'] < 0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe746b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_constraint_phisics(pred2, a, b)\n",
    "\n",
    "\n",
    "#ça à l'air d'aller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a2dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
